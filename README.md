# Spendalyzer - A Bank Statement Analytics Application
* 2nd Place Winner at the Cornell SC Johnson Data Science Showcase on May 22, 2023

## About
* Our motivation to address this problem stemmed from our research on the growing credit card debt in the United States and the lack of predictive and prescriptive analytics in budgeting and personal finance apps. While you may receive information on your spending and where it occurs, you typically don't receive real-time feedback on which categories to cut back on, personalized strategies to adopt, or an understanding of your strengths and weaknesses. We specifically focus our solution on low-income households who disproportionately take on more debt than other income segments.<br>
* Our solution incorporates the OKR and KPI measurement framework to track spending data and establish a realistic budget. We utilize ML models like Naive Bayes to classify transactions as necessities or not, advanced forecasting methods to predict categories of overspending and prescribe strategies to take, gamification to encourage healthy spending habits, and a Chrome Extension that analyzes your recent purchase history and engages System 2 (deliberate thinking) to prevent impulse purchases.<br>
* Used pandas, numpy, dash, nltk, panel, and plotly libraries for data wrangling, data visualizations, web application framework, ML algorithms, and dashboard deployment.
![Dashboard](/images/dashboard.jpeg)
![Spendalyzer](/images/Spendalyzer.png)
![Recommendations](/images/SMA-and-ES-Forecasting.png)

## Preview of Spendalyzer Recommendations (Backed by consumer behavior studies)
**Suggested strategies to curb impulse purchases**
1. Consider eating before shopping to avoid impulse purchases (studies have demonstrated that satiation through food consumption prior to shopping can help individuals adhere to their shopping lists and resist unplanned impulse purchases)
2. Purchase your groceries online (studies show that shopping at online grocery platforms reduces the consumption of impulse purchases)
3. Use physical cash in an envelope when shopping at a grocery store (studies have shown that the physical presence of cash and the increased pain of paying reduces impulsive purchases aka loss aversion)  

## Researching Exponential Smoothing vs. Moving Average
* For the application, we use both exponential smoothing and moving average forecasts to identify patterns and trends in the data. While both methods are useful for smoothing out fluctuations in a time series, they differ in how they weight historical data. Moving average is a simple and effective method for identifying trends and removing random fluctuations in the data. We use a fixed number of past data points, referred to as the "window size," to calculate the moving average.
* While moving average and exponential smoothing is a good start, the forecasts can be drastiaclly improved by comparing MAPE, MAD, or MSE. From a spending context our current solution fails to capture economic factors, seasonality, and personalization that occurs with spending. As such ARIMA, Holt-Winters, regression, and time series decomposition are better forecasting methods to exponential smoothing and moving averages for the following reasons:
  * ARIMA (Autoregressive Integrated Moving Average): ARIMA is a powerful forecasting method that can handle time series data with complex patterns, trends, and seasonality. It is suitable when the data exhibits non-linear behavior and has a combination of autoregressive (AR), moving average (MA), and integrated (I) components. In the Spendalyzer application, ARIMA can capture the dependencies and patterns in spending data that may not be adequately addressed by simple moving averages or exponential smoothing. It can provide more accurate and robust predictions, especially when dealing with data affected by economic factors like interest rates and inflation.
  * Holt-Winters: Holt-Winters method is specifically designed for time series data with trend and seasonality. It extends exponential smoothing to incorporate both the trend and seasonal components. In the Spendalyzer application, where the spending patterns might exhibit both long-term trends and seasonal variations, Holt-Winters can capture these patterns effectively. It allows for more accurate forecasts and enables the identification of specific categories of overspending that might occur at certain times of the year.
  * Regression: Regression analysis can be useful in the Spendalyzer application to understand the relationship between spending and other relevant factors, such as income, age, location, or any other available demographic or personal data. By using regression, the application can determine how different variables impact spending behavior and make personalized recommendations based on individual characteristics. It allows for a deeper understanding of the underlying factors that drive spending patterns and helps in developing more tailored strategies for budgeting and personal finance.
  * Time Series Decomposition: Time series decomposition techniques, such as seasonal decomposition of time series (STL) or X-12-ARIMA, are useful when the data exhibits multiple components, such as trend, seasonality, and residual. By decomposing the time series into its constituent parts, it becomes easier to analyze and model each component separately. In the Spendalyzer application, time series decomposition can help identify specific seasonal patterns, understand the long-term trends in spending, and analyze the residual component for any irregular or unpredictable behavior. It provides a more comprehensive view of the underlying patterns in the data, which can improve the accuracy of predictions and recommendations.

## Naive Bayes Text Classifier (classifying transactions as necessities or not)
* Data Preparation: Prepare a labeled dataset where each transaction is associated with its corresponding class (necessity or non-necessity).
* Text Preprocessing: Preprocess the transaction text to remove noise and standardize the data. This typically involves steps such as removing punctuation, converting text to lowercase, removing stop words, and performing stemming or lemmatization to reduce words to their base form.
* Feature Extraction: Transform the preprocessed transaction text into numerical feature vectors that can be used by the Naive Bayes classifier. One common approach is to use the Bag-of-Words model, where each transaction is represented as a vector of word frequencies or presence indicators.
* Training the Naive Bayes Classifier: Split the labeled dataset into a training set and a validation set. Use the training set to train the Naive Bayes classifier on the transaction features and their corresponding labels. The classifier learns the conditional probabilities of each word given a class (necessity or not).
* Model Evaluation: Evaluate the trained Naive Bayes classifier using the validation set. Calculate metrics such as accuracy, precision, recall, and F1-score to assess the classifier's performance in classifying transactions.
* Prediction and Classification: Once the Naive Bayes classifier is trained and evaluated, it can be used to predict the class (necessity or not) of new, unseen transactions. Apply the same preprocessing and feature extraction steps to the new transaction text and use the trained classifier to predict its class based on the calculated probabilities.
* Integration with Spendalyzer Application: Integrate the trained Naive Bayes classifier into the Spendalyzer application. When a new transaction is received, pass its text through the classifier to determine whether it is classified as a necessity or not. Based on the classification result, provide appropriate feedback, recommendations, or strategies to the user.

## Next Steps
* For next steps, we can predict the likelihood of an individual sticking to the budget based on their historical data and performance. These predictions can help identify individuals who are more likely to struggle with budget adherence.
